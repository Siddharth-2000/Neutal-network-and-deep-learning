{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adb10d9e",
   "metadata": {},
   "source": [
    "### Importing the Libraries that are necessary to Train an Test the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "9e21e5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5b6a43",
   "metadata": {},
   "source": [
    "### Loading the necessary glass data to apply the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "eacae290",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('glass.csv') #reading and loading the csv format glass data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552ed363",
   "metadata": {},
   "source": [
    "### Seeing for the first five parameters to have a brief description regarding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1ffca774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RI     Na    Mg    Al     Si     K    Ca   Ba   Fe  Type\n",
       "0  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0     1\n",
       "1  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0     1\n",
       "2  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0     1\n",
       "3  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0     1\n",
       "4  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0     1"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "9263e0f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.518365</td>\n",
       "      <td>13.407850</td>\n",
       "      <td>2.684533</td>\n",
       "      <td>1.444907</td>\n",
       "      <td>72.650935</td>\n",
       "      <td>0.497056</td>\n",
       "      <td>8.956963</td>\n",
       "      <td>0.175047</td>\n",
       "      <td>0.057009</td>\n",
       "      <td>2.780374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.003037</td>\n",
       "      <td>0.816604</td>\n",
       "      <td>1.442408</td>\n",
       "      <td>0.499270</td>\n",
       "      <td>0.774546</td>\n",
       "      <td>0.652192</td>\n",
       "      <td>1.423153</td>\n",
       "      <td>0.497219</td>\n",
       "      <td>0.097439</td>\n",
       "      <td>2.103739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.511150</td>\n",
       "      <td>10.730000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>69.810000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.430000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.516522</td>\n",
       "      <td>12.907500</td>\n",
       "      <td>2.115000</td>\n",
       "      <td>1.190000</td>\n",
       "      <td>72.280000</td>\n",
       "      <td>0.122500</td>\n",
       "      <td>8.240000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.517680</td>\n",
       "      <td>13.300000</td>\n",
       "      <td>3.480000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>72.790000</td>\n",
       "      <td>0.555000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.519157</td>\n",
       "      <td>13.825000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>1.630000</td>\n",
       "      <td>73.087500</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>9.172500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.533930</td>\n",
       "      <td>17.380000</td>\n",
       "      <td>4.490000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>75.410000</td>\n",
       "      <td>6.210000</td>\n",
       "      <td>16.190000</td>\n",
       "      <td>3.150000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               RI          Na          Mg          Al          Si           K  \\\n",
       "count  214.000000  214.000000  214.000000  214.000000  214.000000  214.000000   \n",
       "mean     1.518365   13.407850    2.684533    1.444907   72.650935    0.497056   \n",
       "std      0.003037    0.816604    1.442408    0.499270    0.774546    0.652192   \n",
       "min      1.511150   10.730000    0.000000    0.290000   69.810000    0.000000   \n",
       "25%      1.516522   12.907500    2.115000    1.190000   72.280000    0.122500   \n",
       "50%      1.517680   13.300000    3.480000    1.360000   72.790000    0.555000   \n",
       "75%      1.519157   13.825000    3.600000    1.630000   73.087500    0.610000   \n",
       "max      1.533930   17.380000    4.490000    3.500000   75.410000    6.210000   \n",
       "\n",
       "               Ca          Ba          Fe        Type  \n",
       "count  214.000000  214.000000  214.000000  214.000000  \n",
       "mean     8.956963    0.175047    0.057009    2.780374  \n",
       "std      1.423153    0.497219    0.097439    2.103739  \n",
       "min      5.430000    0.000000    0.000000    1.000000  \n",
       "25%      8.240000    0.000000    0.000000    1.000000  \n",
       "50%      8.600000    0.000000    0.000000    2.000000  \n",
       "75%      9.172500    0.000000    0.100000    3.000000  \n",
       "max     16.190000    3.150000    0.510000    7.000000  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "b3169af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RI      0\n",
      "Na      0\n",
      "Mg      0\n",
      "Al      0\n",
      "Si      0\n",
      "K       0\n",
      "Ca      0\n",
      "Ba      0\n",
      "Fe      0\n",
      "Type    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())  # Check for null values\n",
    "data.fillna(data.mean(), inplace=True)  # Replacing all the null values with the mean data for the particular column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22350e6",
   "metadata": {},
   "source": [
    "### Splitting the Data into training and testing parts with training data as 80% and 20% for Testing for the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "2fdb4ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Type', axis=1)  # Extracting attributes, excluding 'Type' column\n",
    "y = data['Type']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) #shuffling the data and using the splitting techique to segregate into train and test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7761b2c5",
   "metadata": {},
   "source": [
    "### Normalizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "023a0300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement feature scaling using StandardScaler for data normalization.\n",
    "# This step helps the algorithm perform better by standardizing feature scales.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Create a StandardScaler instance for feature scaling.\n",
    "scaler = StandardScaler()\n",
    "# Normalize the training data.\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "# Normalize the testing data using the same scaler.\n",
    "X_test = scaler.transform(X_test)\n",
    "# End of feature scaling process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953a5a35",
   "metadata": {},
   "source": [
    "### Applying the classifier Algorithm Linear Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "0c2f8d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-25 {color: black;}#sk-container-id-25 pre{padding: 0;}#sk-container-id-25 div.sk-toggleable {background-color: white;}#sk-container-id-25 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-25 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-25 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-25 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-25 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-25 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-25 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-25 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-25 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-25 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-25 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-25 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-25 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-25 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-25 div.sk-item {position: relative;z-index: 1;}#sk-container-id-25 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-25 div.sk-item::before, #sk-container-id-25 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-25 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-25 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-25 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-25 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-25 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-25 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-25 div.sk-label-container {text-align: center;}#sk-container-id-25 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-25 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-25\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=5, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" checked><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=5, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=5, kernel='linear')"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the SVM classifier with a linear kernel and a regularization parameter C of 5.\n",
    "svm_class = SVC(kernel='linear', C=5) \n",
    "# Train the SVM classifier on the training data.\n",
    "svm_class.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b36ea5",
   "metadata": {},
   "source": [
    "### predicting for the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "447400c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_classifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a67326",
   "metadata": {},
   "source": [
    "### Finding the accuracy percent how correctly it predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "dc163ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Linear SVM model for the data after applying the algorith: 76.74\n"
     ]
    }
   ],
   "source": [
    "acc = round(svm_class.score(X_test, y_test) * 100, 2)\n",
    "print(f\"Accuracy of the Linear SVM model for the data after applying the algorith: {acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acc7da0",
   "metadata": {},
   "source": [
    "### Looking for various features of classification report generated like precision, f1-score and seeing the accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d9eb2bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.82      0.75        11\n",
      "           2       0.69      0.79      0.73        14\n",
      "           3       1.00      0.00      0.00         3\n",
      "           5       0.80      1.00      0.89         4\n",
      "           6       1.00      0.67      0.80         3\n",
      "           7       1.00      0.88      0.93         8\n",
      "\n",
      "    accuracy                           0.77        43\n",
      "   macro avg       0.86      0.69      0.68        43\n",
      "weighted avg       0.80      0.77      0.74        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, y_pred, zero_division=1)\n",
    "\n",
    "print(\"Classification Report for the data:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917e7bcb",
   "metadata": {},
   "source": [
    "## We can conclude that the highest accuracy found is 77% accuracy for the test data and the accuracy is higher for SVM than Naive Bayes and the reasons are mentioned in the pdf attached below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9270f267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e2f051",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
